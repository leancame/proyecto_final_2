# Configuración de CUDA según tu GPU
TORCH_CUDA_ARCH_LIST=7.5

# Puertos de la aplicación
HOST_PORT=7860
CONTAINER_PORT=7860
HOST_API_PORT=5000
CONTAINER_API_PORT=5000

# Extensiones a compilar
BUILD_EXTENSIONS=llama-cpp

# Variables de caché
TRANSFORMERS_CACHE=/home/app/text-generation-webui/cache/
HF_HOME=/home/app/text-generation-webui/cache/
# Token de Hugging Face (NECESARIO para descargar modelos privados o gated como LLaMA 3)
HF_TOKEN=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
